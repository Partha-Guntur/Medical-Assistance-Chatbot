{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqydSD7KgaCF"
      },
      "source": [
        "1. Data Cleaning: Removing any NULL rows or columns.\n",
        "2. Data Preparation: Prepare the training data for the chatbot.\n",
        "3. BERT Embeddings: Use BERT to generate embeddings for the input text.\n",
        "4. LSTM Model: Build and train an LSTM model for generating responses.\n",
        "5. Chatbot Integration: Combine BERT and LSTM for the chatbot functionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pS6V9nbHP_iV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "dataset = load_dataset(\"ruslanmv/ai-medical-chatbot\")\n",
        "train_data = dataset[\"train\"]\n",
        "\n",
        "# For this demo, let's choose the first 1000 dialogues\n",
        "df = pd.DataFrame(train_data)\n",
        "df = df[[\"Description\", \"Doctor\"]].rename(columns={\"Description\": \"question\", \"Doctor\": \"answer\"})\n",
        "\n",
        "# Clean the question and answer columns\n",
        "df['question'] = df['question'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
        "df['answer'] = df['answer'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "question    0\n",
              "answer      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "question    0.0\n",
              "answer      0.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.loc[df['question']==df['answer']].sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradio Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def chat(message, history):\n",
        "  response = rag_chain.invoke(message)\n",
        "  return response\n",
        "\n",
        "# Create a Gradio interface\n",
        "with gr.Blocks() as interface:\n",
        "  # Display a welcome message (implementation omitted for brevity)\n",
        "  with gr.Row():\n",
        "    with gr.Column():\n",
        "      text_prompt = gr.Textbox(label=\"Input Prompt\", placeholder=\"Example: What are the symptoms of COVID-19?\", lines=2)\n",
        "      generate_button = gr.Button(\"Ask Me\", variant=\"primary\")\n",
        "  with gr.Row():\n",
        "    answer_output = gr.Textbox(type=\"text\", label=\"Answer\")\n",
        "  generate_button.click(chat, inputs=[text_prompt], outputs=answer_output)\n",
        "\n",
        "# Launch the Gradio interface\n",
        "interface.launch(server_name=\"0.0.0.0\", server_port=7000, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
